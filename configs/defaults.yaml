epochs: 400
batch_size: 32 # per-GPU batch size
n_landmarks: 30 # number of landmarks to learn
dataset: ''
dataset_path: ''
save_path: ''
resume_ckpt: ''
resume_ckpt_D: "" # discriminator checkpoint
resume_ckpt_opt_G: "" # optimizer checkpoint for main model
resume_ckpt_opt_D: "" # optimizer checkpoint for discriminator
img_size: 128 # images will be resized to this size
disable_spade: False
weight_decay: 0.000005
use_DDP: False # enables distributed data-parallel
torch_home: '' # path to where vgg pre-trained weights will be cached
num_workers: 2 # dataloader workers
color_jitter: True
model: 'PartFactorizedModel'
learning_rate : 0.001
vgg_lambda: 1.0 # weighting for vgg style loss term
use_gan: False # GAN loss term (better reconstruction, less accurate landmarks)
use_vgg: True # vgg style loss for reconstruction
no_grad_clip: False # disable gradient clipping
reduced_w: False # use non-uniform weighting scheme for VGG layer loss
num_D: 2 # number of discriminators to use
n_layers_D: 3 # only used if which_model_netD == n_layers
no_lsgan: False # disables lsgan in favor of BCE
n_filters: 32 # number of channels for appearance encoding
ndf: 64 #number of discrim filters in first conv layer
ngc: 64
nsf: 6 # number of filters in the first conv layer of shape encoder
naf: 0 # number of filters in the first layer of appearance
local_rank: 0
val_frac: 0.01 # take the first 1% of the validation set only
save_freq: 2 # checkpoint frequency during training by eoch
val_freq: 4 # validation frequency during training by epoch
flip_probability: 0.0 # probability for left/right flipping during training
color_jitter_targets: False # apply color jittering on the targets first
trans_lb: -10 # TPS warping random translation range
trans_ub: 10
scale_lb: 1.05 # TPS warping random scaling range (larger means shrink more)
scale_ub: 1.15
rot_lb: -0.39269908169872414 # -pi/8 # TPS warping random rotation range
rot_ub: 0.39269908169872414  # pi/8
use_identity_covariance: False # if True, all landmark gaussians will be isotropic with fixed covariance
fixed_covar: 0.05 # covar diagonal value if use_identity_covariance
use_warped: False # warping augmentating during training
use_temporal: False # temporal sampling during training
use_fg_bg_mask: False # use foreground-background separation masks
low_res_mask: False # use quarter resolution for separation mask (necessary for KTH or any grayscale image dataset)
